{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efaab5b8",
   "metadata": {},
   "source": [
    "# 2020-2021 County level data analysis\n",
    "## Hindsait\n",
    "\n",
    " https://data.hrsa.gov/data/download?data=AHRF#AHRF\n",
    "\n",
    "### Details:\n",
    "- federal Health Resource and Service Administration makes available the Area Health Resource File (AHRF) database - a comprehensive county-level database of demographic and available health-care options nationwide\n",
    "\n",
    "### Output:\n",
    "- I would like you to write a python class to parse this file and pull and normalize data as best as you can\n",
    "- write simple utilities wherein we can gather some salient demographic and health care details at county level or state level from such reduced data files\n",
    "- export data to CSV files\n",
    "- analysis as jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6538b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "package import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "# import hlvl_util as hlvl\n",
    "# from hlvl import standardize_data, create_year_column, create_var_legend\n",
    "from sas7bdat import SAS7BDAT \n",
    "\n",
    "def standardize_data(vals):\n",
    "    # lowercase standardization\n",
    "    cols = vals\n",
    "    for i in range(len(cols)):\n",
    "    #     print(i)\n",
    "        lowercase = cols[i].lower()\n",
    "        lowercase = lowercase.strip()\n",
    "    #         print(lowercase)\n",
    "        cols[i] = lowercase\n",
    "        cols[i] = cols[i].replace(' ', '_')\n",
    "        cols[i].replace('/', '')\n",
    "    #replacing all dashes with underscores\n",
    "        cols[i] = cols[i].replace('-', '_')\n",
    "        cols[i] = cols[i].replace('______', '_')\n",
    "        cols[i] = cols[i].replace('___', '_')\n",
    "        cols[i] = cols[i].replace('__', '_')\n",
    "        \n",
    "    return cols\n",
    "\n",
    "def create_year_column(input_df):\n",
    "    #     input_df = non_health_vars\n",
    "    has_years_idx = list(input_df[input_df.var_id.str.contains('_') == True].index)\n",
    "    no_years_idx = list(input_df[input_df.var_id.str.contains('_') == False].index)\n",
    "\n",
    "    input_df['data_year'] = 0\n",
    "    #     input_df.loc[has_years_idx, 'data_year'] = \n",
    "    #         print(input_df.loc[has_years_idx, 'var_id'].str.split('_'))\n",
    "    input_df.loc[has_years_idx, 'var_id'] = input_df.loc[has_years_idx, 'var_id'].str.split('_')\n",
    "    #     print(input_df.var_id)\n",
    "    input_df.data_year = input_df.var_id.astype('int', errors='ignore')\n",
    "    #     print(input_df.data_year)\n",
    "    take_year = lambda x: x[1]\n",
    "    # print(input_df.loc[has_years_idx, 'data_year'])\n",
    "    # print(input_df.data_year)\n",
    "    for i in has_years_idx:\n",
    "        year = int(input_df.loc[i, 'data_year'][1])\n",
    "    #     print(year)\n",
    "        input_df.loc[i, 'data_year'] = int(year)\n",
    "    # print(input_df)\n",
    "    input_df.loc[no_years_idx, 'data_year'] = 0\n",
    "\n",
    "    for i in has_years_idx:\n",
    "        var_id = input_df.loc[i, 'var_id'][0]\n",
    "        input_df.loc[i, 'var_id'] = var_id\n",
    "    # print(input_df)\n",
    "    output_df = input_df.copy()\n",
    "    return output_df\n",
    "\n",
    "def create_var_legend(input_file, file_type, delimiter='\\t'):\n",
    "    # importing data from documentation to create zipped variable dictionary\n",
    "    #importing the var info chart from txt; copied var chart to new file\n",
    "    txt_dict = input_file[1]\n",
    "    dtype = file_type[1]\n",
    "    \n",
    "    if dtype == 'sas':\n",
    "        #importing data from sas file as dataframe\n",
    "        with SAS7BDAT(file, skip_header=False) as reader:\n",
    "            df = reader.to_data_frame()\n",
    "    elif dtype == 'csv':\n",
    "        #importing data from csv file as dataframe\n",
    "        txt_dict = filepath\n",
    "        df = pd.read_csv(txt_dict, sep=delimiter)\n",
    "\n",
    "    idx = txt[txt.FIELD.str.startswith('*') == True].index\n",
    "\n",
    "    #dropping rows with only asterisk dividers\n",
    "    var_legend = txt.drop(index=idx, axis=0)\n",
    "    # looking at var df without starred rows & creating a field_cat category/section each field falls under\n",
    "    # var_legend = txt.loc[idx, :]\n",
    "    # print(var_legend.head())\n",
    "    legend_df = var_legend.copy()\n",
    "\n",
    "    idx = legend_df[legend_df['VARIABLE NAME'].isna() == True].index\n",
    "    legend_df.drop(index=idx, inplace=True)\n",
    "    # legend_df.head()\n",
    "\n",
    "    drops = var_legend.FIELD[idx]\n",
    "    drops = drops[drops.str.startswith('*') == False]\n",
    "    drops = drops[drops.str.startswith('   ') == False]\n",
    "    # print(drops)\n",
    "\n",
    "    legend_df['field_category'] = 0\n",
    "    legend_df.head()\n",
    "\n",
    "    for idx in (drops.index):\n",
    "        cat = str(drops[[idx]].values)\n",
    "        legend_df.loc[idx:, 'field_category'] = cat\n",
    "\n",
    "    legend_df.field_category = legend_df.field_category.str.slice(2,-2)\n",
    "    # legend_df.field_category.fillna('none', inplace=True)\n",
    "    # legend_df.head(50)\n",
    "\n",
    "    idx = legend_df[legend_df.FIELD != 'FIELD']\n",
    "    variable_legend = idx.copy()\n",
    "    # variable_legend.head()\n",
    "\n",
    "    variable_legend.columns = standardize_data(list(variable_legend.columns))\n",
    "    variable_legend.fillna('na', inplace=True)\n",
    "    # print(variable_legend.head())\n",
    "\n",
    "    variable_legend.field_category = standardize_data(list(variable_legend.field_category))\n",
    "    # print(variable_legend.field_category.unique())\n",
    "\n",
    "    variable_legend.field = standardize_data(list(variable_legend.field))\n",
    "    # variable_legend.head()\n",
    "    variable_legend.field = variable_legend.field.str.replace('_', '')\n",
    "    legend_dict = dict(zip(list(variable_legend.field), standardize_data(list(variable_legend.variable_name))))\n",
    "    \n",
    "    export_df = pd.DataFrame([list(legend_dict), list(legend_dict.values())]).T\n",
    "    export_df.columns = ['var_id', 'var_name']\n",
    "    # export_df.head()\n",
    "\n",
    "    export_df_w_year = create_year_column(export_df)\n",
    "    export_df_w_year.to_csv('feature_vars/variable_legend.csv')\n",
    "    \n",
    "    return export_df_w_year\n",
    "\n",
    "def create_dataframe(input_file, file_type, delimiter='\\t'):\n",
    "    dtype = health_lvl.file_type[0]\n",
    "    file = health_lvl.input_data[0]\n",
    "    if dtype == 'sas':\n",
    "        #importing data from sas file as dataframe\n",
    "        with SAS7BDAT(file, skip_header=False) as reader:\n",
    "            df = reader.to_data_frame()\n",
    "    elif dtype == 'csv':\n",
    "        #importing data from csv file as dataframe\n",
    "        txt_dict = filepath\n",
    "        txt = pd.read_csv(txt_dict, sep=delimiter)\n",
    "\n",
    "    with SAS7BDAT(file, skip_header=False) as reader:\n",
    "        df = reader.to_data_frame()\n",
    "\n",
    "    # insert null rates across variables\n",
    "    na_rates = df.isna().mean().sort_values(ascending=False)\n",
    "    na_rates = pd.DataFrame([na_rates.index, list(na_rates)]).T\n",
    "    na_rates.columns = ['var_id', 'null_rate']\n",
    "#         na_rates.head()\n",
    "\n",
    "    # merge null rates into dataframe\n",
    "    trans_df = df.T\n",
    "    trans_df = trans_df.reset_index().rename(columns={'index':'var_id'})\n",
    "    tdf = trans_df.merge(na_rates, how='left')\n",
    "    tdf.set_index('var_id', inplace=True)\n",
    "    df_updated = tdf.T\n",
    "#         df_updated.head()\n",
    "    df_updated.to_csv('feature_vars/updated_dataframe.csv')\n",
    "    return df_updated\n",
    "\n",
    "def filter_input_features(df_updated, feature_list, var_legend):\n",
    "    non_health_vars = pd.read_csv('feature_vars/non_health_vars.csv', index_col=0)\n",
    "    health_vars = pd.read_csv('feature_vars/health_vars.csv', index_col=0)\n",
    "    misc_vars = pd.read_csv('feature_vars/misc_vars.csv', index_col=0)\n",
    "\n",
    "    non_health_vars.data_year.fillna(0, inplace=True)\n",
    "\n",
    "    # non_health_vars_w_year = create_year_column(non_health_vars)\n",
    "    non_health_vars.data_year = non_health_vars.data_year.astype('int')\n",
    "\n",
    "    features_df = pd.concat(feature_list)\n",
    "    features_df['var_year_id'] = features_df.var_id.astype('str', errors='ignore') + (features_df.data_year.astype('int', errors='ignore')).astype('str')\n",
    "    features_df.var_year_id\n",
    "#     features_df\n",
    "    # filtering out all fields that are not in the non_health and health variable lists selected prevesiously\n",
    "    var_list = [val for val in list(df_updated.columns) if val in (list(features_df.var_year_id) + list(features_df.var_id))]\n",
    "    # len(var_list)\n",
    "\n",
    "    filtered_vars = df_updated[var_list]\n",
    "#     filtered_vars\n",
    "\n",
    "# renaming the feature variable column names with the variable name dictionary (legend_dict) created earlier\n",
    "    filtered_vars = filtered_vars.rename(columns = legend_dict)\n",
    "    return filtered_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee079f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class health_lvl():\n",
    "    \n",
    "    def __init__(self, level_description):\n",
    "        health_lvl.level_description = level_description\n",
    "        #package import\n",
    "#         import numpy as np\n",
    "#         import pandas as pd\n",
    "        # import seaborn as sns\n",
    "#         import plotly.express as px\n",
    "#         import hlvl_util as hlvl\n",
    "#         from hlvl import standardize_data, create_year_column, create_var_legend\n",
    "#         from sas7bdat import SAS7BDAT \n",
    "\n",
    "\n",
    "    def data_init(self, filepath, file_type=['sas', 'csv']):\n",
    "        health_lvl.input_data = filepath\n",
    "        health_lvl.file_type = file_type\n",
    "\n",
    "        health_lvl.data = create_dataframe(health_lvl.input_data, health_lvl.file_type)\n",
    "        health_lvl.var_data = create_var_legend(health_lvl.input_data, health_lvl.file_type)\n",
    "        return health_lvl.data, health_lvl.var_data         \n",
    "                 \n",
    "    def set_feature_list(self, features_list):\n",
    "        health_lvl.feaures = filter_input_features(health_lvl.data, health_lvl.var_data, features_list)\n",
    "        return health_lvl.feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd2384a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
